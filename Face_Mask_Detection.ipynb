{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Face Mask Detection Project\n",
        "\n",
        "This project aims to detect whether a person is wearing a mask or not using a Convolutional Neural Network (CNN). We will use the MobileNetV2 architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Check for GPU availability\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Collection (Kaggle Dataset)\n",
        "\n",
        "We use the [Face Mask Dataset](https://www.kaggle.com/omkargurav/face-mask-dataset). Ensure you have `kaggle.json` in the working directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install Kaggle library if not already installed\n",
        "# !pip install kaggle\n",
        "\n",
        "# Configure Kaggle API\n",
        "if os.path.exists('kaggle.json'):\n",
        "    os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
        "    # Download dataset\n",
        "    !kaggle datasets download -d omkargurav/face-mask-dataset\n",
        "else:\n",
        "    print(\"kaggle.json not found. Please upload it to the current directory to download the dataset.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "# Extract the dataset\n",
        "dataset_zip = 'face-mask-dataset.zip'\n",
        "if os.path.exists(dataset_zip):\n",
        "    with zipfile.ZipFile(dataset_zip, 'r') as zip_ref:\n",
        "        zip_ref.extractall('data')\n",
        "    print(\"Dataset extracted to ./data\")\n",
        "else:\n",
        "    print(f\"{dataset_zip} not found. Ensure download was successful.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with_mask_files = []\n",
        "without_mask_files = []\n",
        "\n",
        "data_path = 'data/data' # The extraction often creates a nested 'data' folder, adjust as needed based on zip structure\n",
        "if not os.path.exists(os.path.join(data_path, 'with_mask')):\n",
        "    # Fallback if structure is just data/with_mask\n",
        "    data_path = 'data'\n",
        "\n",
        "with_mask_path = os.path.join(data_path, 'with_mask')\n",
        "without_mask_path = os.path.join(data_path, 'without_mask')\n",
        "\n",
        "if os.path.exists(with_mask_path):\n",
        "    with_mask_files = os.listdir(with_mask_path)\n",
        "    print('Number of with mask images:', len(with_mask_files))\n",
        "else:\n",
        "    print(\"Path not found:\", with_mask_path)\n",
        "\n",
        "if os.path.exists(without_mask_path):\n",
        "    without_mask_files = os.listdir(without_mask_path)\n",
        "    print('Number of without mask images:', len(without_mask_files))\n",
        "else:\n",
        "    print(\"Path not found:\", without_mask_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Labels\n",
        "# 1 - With Mask\n",
        "# 0 - Without Mask\n",
        "\n",
        "with_mask_labels = [1] * len(with_mask_files)\n",
        "without_mask_labels = [0] * len(without_mask_files)\n",
        "\n",
        "labels = with_mask_labels + without_mask_labels\n",
        "\n",
        "print(\"Total labels:\", len(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Images\n",
        "data = []\n",
        "\n",
        "# Use a smaller subset if memory is an issue, or load all\n",
        "# Resizing images to 128x128 for MobileNetV2 inputs\n",
        "\n",
        "def load_images(file_list, path):\n",
        "    for img_file in file_list:\n",
        "        image = cv2.imread(os.path.join(path, img_file))\n",
        "        if image is not None:\n",
        "            image = cv2.resize(image, (128, 128))\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            data.append(image)\n",
        "        else:\n",
        "            # If image fails to load, we should remove its corresponding label to keep lengths consistent\n",
        "            # But simplest here is to just skip and assume mostly clean data\n",
        "            pass\n",
        "\n",
        "print(\"Loading 'with_mask' images...\")\n",
        "load_images(with_mask_files, with_mask_path)\n",
        "\n",
        "print(\"Loading 'without_mask' images...\")\n",
        "load_images(without_mask_files, without_mask_path)\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X = np.array(data)\n",
        "Y = np.array(labels)\n",
        "\n",
        "print(\"Data shape:\", X.shape)\n",
        "print(\"Labels shape:\", Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalize the data\n",
        "X = X / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split into Train and Test\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Train shape:\", X_train.shape)\n",
        "print(\"Test shape:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model Building (MobileNetV2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_of_classes = 2\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(128,128,3)))\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(num_of_classes, activation='sigmoid'))  # Using sigmoid inside SparseCategoricalCrossentropy logic or softmax\n",
        "# Actually for 2 classes (binary-like but treating as sparse categorical), we use softmax with 2 units or sigmoid with 1 unit.\n",
        "# Let's stick to the previous user's likely approach: Softmax with 2 units\n",
        "model.add(layers.Dense(2, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = model.fit(X_train, Y_train, validation_split=0.1, epochs=5, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(X_test, Y_test)\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plotting Loss and Accuracy\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Predictive System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_mask(image_path):\n",
        "    input_image = cv2.imread(image_path)\n",
        "    if input_image is None:\n",
        "        print(\"Could not read image\")\n",
        "        return\n",
        "        \n",
        "    plt.imshow(cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB))\n",
        "    plt.show()\n",
        "\n",
        "    input_image_resized = cv2.resize(input_image, (128,128))\n",
        "    input_image_scaled = input_image_resized / 255.0\n",
        "    input_image_reshaped = np.reshape(input_image_scaled, [1,128,128,3])\n",
        "\n",
        "    input_prediction = model.predict(input_image_reshaped)\n",
        "    input_pred_label = np.argmax(input_prediction)\n",
        "\n",
        "    if input_pred_label == 1:\n",
        "        print(\"Prediction: The person is wearing a Mask\")\n",
        "    else:\n",
        "        print(\"Prediction: The person is NOT wearing a Mask\")\n",
        "\n",
        "# Example usage (replace with actual image path after running cells)\n",
        "# predict_mask('data/with_mask/with_mask_1545.jpg')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}